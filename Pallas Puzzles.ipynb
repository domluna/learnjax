{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07572c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "from typing import Callable\n",
    "\n",
    "import jax\n",
    "from jax.experimental import pallas as pl\n",
    "# from jax.experimental.pallas import tpu as pltpu\n",
    "from jax import random\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0068537e",
   "metadata": {},
   "source": [
    "I'm doing these on a GTX 3090. 99KB of shared memory is available for each thread block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa2f942",
   "metadata": {},
   "source": [
    "### Constant Add Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7230f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constant_vector_add_kernel(x_ref, y_ref, out_ref):\n",
    "    out_ref[...] = x_ref[...] + y_ref[...]\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=(\"b\"))\n",
    "def constant_vector_add(\n",
    "    x: jax.Array,\n",
    "    y: jax.Array,\n",
    "    *,\n",
    "    b: int = 128,\n",
    "):\n",
    "    \n",
    "    assert(x.shape == y.shape)\n",
    "    assert(len(x.shape) == 1)\n",
    "    print(b)\n",
    "    m = x.shape[0]\n",
    "    return pl.pallas_call(\n",
    "        constant_vector_add_kernel,\n",
    "        out_shape=jax.ShapeDtypeStruct((m,), x.dtype),\n",
    "        in_specs=[\n",
    "            pl.BlockSpec(lambda i: (i,), (b,)),\n",
    "            pl.BlockSpec(lambda i: (i,), (b,)),\n",
    "        ],\n",
    "        out_specs= pl.BlockSpec(lambda i: (i,), (b,)),\n",
    "        grid=(m // b,),\n",
    "    )(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6733f9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(True, dtype=bool)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2**20 # 1M elements\n",
    "x = jnp.ones(N, dtype=jnp.float16)\n",
    "y = jnp.ones(N, dtype=jnp.float16)\n",
    "\n",
    "out1 = constant_vector_add(x, y)\n",
    "out2 = x + y\n",
    "jnp.allclose(out1, out2, atol=1e-2, rtol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69649591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2**15 = 32768\n",
    "%timeit constant_vector_add(x, y, b=2**12).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "381998b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.3 µs ± 3.06 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit (x + y).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9bef5d",
   "metadata": {},
   "source": [
    "No matter the block size I don't get this error\n",
    "\n",
    "λ ~/code/learnjax: python3 pallas.py 4096 --block_size 512\n",
    "4096 4096 4096\n",
    "(8, 8, 8)\n",
    "Traceback (most recent call last):\n",
    "  File \"/home/dom/code/learnjax/pallas.py\", line 72, in <module>\n",
    "    fire.Fire(main)\n",
    "  File \"/home/dom/.local/lib/python3.11/site-packages/fire/core.py\", line 141, in Fire\n",
    "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
    "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/home/dom/.local/lib/python3.11/site-packages/fire/core.py\", line 475, in _Fire\n",
    "    component, remaining_args = _CallAndUpdateTrace(\n",
    "                                ^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/home/dom/.local/lib/python3.11/site-packages/fire/core.py\", line 691, in _CallAndUpdateTrace\n",
    "    component = fn(*varargs, **kwargs)\n",
    "                ^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/home/dom/code/learnjax/pallas.py\", line 58, in main\n",
    "    result = matmul(\n",
    "             ^^^^^^^\n",
    "jaxlib.xla_extension.XlaRuntimeError: RESOURCE_EXHAUSTED: Shared memory size limit exceeded: requested 1115136, available: 101376\n",
    "\n",
    "    Shared memory size limit exceeded\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1398a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array([2., 2., 2., ..., 2., 2., 2.], dtype=float16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_vector_add(x, y, b=2**18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc6310a",
   "metadata": {},
   "source": [
    "I'm not sure why for the addition kernel this doesn't seem to be a problem.\n",
    "\n",
    "Ok, after a bit of digging it seems that there is static and dynamic shared memory types. In a matrix  multiplication kernel only static memory is used and so if it exceeds the size it throws an error. In the addition kernel dynamic memory is used and so this will just stall if the block is too large."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c39a53e",
   "metadata": {},
   "source": [
    "### Puzzle 3: Outer Vector Add\n",
    "\n",
    "Add two vectors.\n",
    "\n",
    "Uses one program block axis. Block size B0 is always the same as vector x length N0. Block size B1 is always the same as vector y length N1.\n",
    "\n",
    "z_ij = x_i + y_j\n",
    "\n",
    "i is rows j is columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "977c3d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = jnp.ones(10).reshape(10, 1)\n",
    "y = jnp.ones(10).reshape(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9a4dc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a71c2863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[8., 8., 8., ..., 8., 8., 8.],\n",
       "       [8., 8., 8., ..., 8., 8., 8.],\n",
       "       [8., 8., 8., ..., 8., 8., 8.],\n",
       "       ...,\n",
       "       [8., 8., 8., ..., 8., 8., 8.],\n",
       "       [8., 8., 8., ..., 8., 8., 8.],\n",
       "       [8., 8., 8., ..., 8., 8., 8.]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def outer_vector_add_kernel(x_ref, y_ref, out_ref):\n",
    "    out_ref[...] = jnp.add(x_ref[...][:, None], y_ref[...][None, :])\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=(\"bm\", \"bn\"))\n",
    "def outer_vector_add(\n",
    "    x: jax.Array,\n",
    "    y: jax.Array,\n",
    "    *,\n",
    "    bm: int = 128,\n",
    "    bn: int = 128,\n",
    "):\n",
    "    m = x.shape[0]\n",
    "    n = y.shape[0]\n",
    "    grid=(m // bm, n // bn)\n",
    "    return pl.pallas_call(\n",
    "        outer_vector_add_kernel,\n",
    "        out_shape=jax.ShapeDtypeStruct((m,n), x.dtype),\n",
    "        in_specs=[\n",
    "            pl.BlockSpec(lambda i, j: (i,), (bm,)),\n",
    "            pl.BlockSpec(lambda i, j: (j,), (bn,)),\n",
    "        ],\n",
    "        out_specs= pl.BlockSpec(lambda i, j: (i,j), (bm,bn)),\n",
    "        grid=grid,\n",
    "#         interpret=True,\n",
    "    )(x, y)\n",
    "\n",
    "x = jnp.ones(4096) + 2\n",
    "y = jnp.ones(4096) + 4\n",
    "outer_vector_add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "89fa9e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[15., 15., 15., ..., 15., 15., 15.],\n",
       "       [15., 15., 15., ..., 15., 15., 15.],\n",
       "       [15., 15., 15., ..., 15., 15., 15.],\n",
       "       ...,\n",
       "       [15., 15., 15., ..., 15., 15., 15.],\n",
       "       [15., 15., 15., ..., 15., 15., 15.],\n",
       "       [15., 15., 15., ..., 15., 15., 15.]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.multiply(x[:, None], y[None, :]).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6f7232c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370 µs ± 7.98 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit jnp.add(x[:, None], y[None, :]).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2f965a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142 µs ± 2.68 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit outer_vector_add(x, y).block_until_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9f06741c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 2048)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_vector_add(x, jnp.ones(2048)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "749e42c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[15. 15. 15. ... 15. 15. 15.]\n",
      " [15. 15. 15. ... 15. 15. 15.]\n",
      " [15. 15. 15. ... 15. 15. 15.]\n",
      " ...\n",
      " [15. 15. 15. ... 15. 15. 15.]\n",
      " [15. 15. 15. ... 15. 15. 15.]\n",
      " [15. 15. 15. ... 15. 15. 15.]]\n"
     ]
    }
   ],
   "source": [
    "### Puzzle 5: Outer Vector Multiplication with Activation\n",
    "\n",
    "def p5_kernel(x_ref, y_ref, z_ref, *, activation):\n",
    "    z_ref[...] = activation(jnp.multiply(x_ref[...][:, None], y_ref[...][None, :]))\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=(\"bm\", \"bn\", \"activation\"))\n",
    "def p5(\n",
    "    x: jax.Array,\n",
    "    y: jax.Array,\n",
    "    *,\n",
    "    bm: int = 128,\n",
    "    bn: int = 128,\n",
    "    activation = jax.nn.relu,\n",
    "):\n",
    "    m = x.shape[0]\n",
    "    n = y.shape[0]\n",
    "    grid=(m // bm, n // bn)\n",
    "    return pl.pallas_call(\n",
    "        functools.partial(p5_kernel, activation=activation),\n",
    "        out_shape=jax.ShapeDtypeStruct((m,n), x.dtype),\n",
    "        in_specs=[\n",
    "            pl.BlockSpec(lambda i, j: (i,), (bm,)),\n",
    "            pl.BlockSpec(lambda i, j: (j,), (bn,)),\n",
    "        ],\n",
    "        out_specs= pl.BlockSpec(lambda i, j: (i,j), (bm,bn)),\n",
    "        grid=grid,\n",
    "#         interpret=True,\n",
    "    )(x, y)\n",
    "\n",
    "x = jnp.ones(4096) + 2\n",
    "y = jnp.ones(4096) - 4\n",
    "res = p5(x, y)\n",
    "# all 0 since 2 * -4 is -8 and relu(-8) = 0\n",
    "print(res)\n",
    "\n",
    "x = jnp.ones(4096) + 2\n",
    "y = jnp.ones(4096) + 4\n",
    "res = p5(x, y)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aee4930",
   "metadata": {},
   "source": [
    "### Puzzle 7: Long Sum\n",
    "\n",
    "Sum of a batch of numbers.\n",
    "\n",
    "Uses one program blocks. Block size B0 represents a range of batches of x of length N0. Each element is of length T. Process it B1 < T elements at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "8dbd6965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "[512. 512. 512. 512.]\n",
      "[512. 512. 512. 512.]\n"
     ]
    }
   ],
   "source": [
    "def p7_kernel(x_ref, z_ref):  \n",
    "    @pl.when(pl.program_id(axis=1) == 0)\n",
    "    def _():\n",
    "        z_ref[...] = jnp.zeros_like(z_ref)    \n",
    "    z_ref[...] += jnp.sum(x_ref[...])\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, static_argnames=(\"block_size\"))\n",
    "def p7(\n",
    "    x: jax.Array,\n",
    "    *,\n",
    "    block_size: int = 128,\n",
    "):\n",
    "    b, m = x.shape\n",
    "    grid=(b, m // block_size)\n",
    "    print(grid)\n",
    "    return pl.pallas_call(\n",
    "        p7_kernel,\n",
    "        in_specs=[\n",
    "            pl.BlockSpec(lambda i, j: (i,j), (None, block_size,)),\n",
    "        ],\n",
    "        out_specs=pl.BlockSpec(lambda i, j: (i,), (1,)),\n",
    "        grid=grid,\n",
    "        out_shape=jax.ShapeDtypeStruct((b,), x.dtype),\n",
    "        interpret=True,\n",
    "    )(x)\n",
    "\n",
    "x = jnp.ones((4, 512))\n",
    "res = p7(x)\n",
    "print(res)\n",
    "print(jnp.sum(x, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "1e881046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(45, dtype=int32, weak_type=True)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.lax.fori_loop(0, 10, lambda i, val: i + val, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303a73f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
